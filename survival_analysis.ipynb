{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8f84fd32",
   "metadata": {},
   "source": [
    "# DeepHit: A Deep Learning Approach to Survival Analysis with Competing Risks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "804efce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from src.model import DeepHit \n",
    "from src.tools import preprocess_metabrics, prepare_deephit_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5d49981e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nx/qw6qn19153l0rb1k4ty684dh0000gn/T/ipykernel_6735/1487857183.py:2: DtypeWarning: Columns (678,688,690,692) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(\"data/METABRIC_RNA_Mutation.csv\")  # example filename\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Loss: 25.6909\n",
      "Epoch 2/50 | Loss: 22.5683\n",
      "Epoch 3/50 | Loss: 19.2246\n",
      "Epoch 4/50 | Loss: 13.5191\n",
      "Epoch 5/50 | Loss: 14.1546\n",
      "Epoch 6/50 | Loss: 14.6311\n",
      "Epoch 7/50 | Loss: 14.8692\n",
      "Epoch 8/50 | Loss: 10.7495\n",
      "Epoch 9/50 | Loss: 12.5307\n",
      "Epoch 10/50 | Loss: 10.3468\n",
      "Epoch 11/50 | Loss: 7.7822\n",
      "Epoch 12/50 | Loss: 11.3699\n",
      "Epoch 13/50 | Loss: 11.4499\n",
      "Epoch 14/50 | Loss: 8.9133\n",
      "Epoch 15/50 | Loss: 11.0006\n",
      "Epoch 16/50 | Loss: 8.9140\n",
      "Epoch 17/50 | Loss: 10.0702\n",
      "Epoch 18/50 | Loss: 10.8099\n",
      "Epoch 19/50 | Loss: 9.1782\n",
      "Epoch 20/50 | Loss: 10.6312\n",
      "Epoch 21/50 | Loss: 11.0518\n",
      "Epoch 22/50 | Loss: 8.1762\n",
      "Epoch 23/50 | Loss: 7.7969\n",
      "Epoch 24/50 | Loss: 9.3407\n",
      "Epoch 25/50 | Loss: 10.1495\n",
      "Epoch 26/50 | Loss: 10.6457\n",
      "Epoch 27/50 | Loss: 9.2338\n",
      "Epoch 28/50 | Loss: 8.1458\n",
      "Epoch 29/50 | Loss: 8.9470\n",
      "Epoch 30/50 | Loss: 9.2013\n",
      "Epoch 31/50 | Loss: 6.0720\n",
      "Epoch 32/50 | Loss: 6.8569\n",
      "Epoch 33/50 | Loss: 8.5290\n",
      "Epoch 34/50 | Loss: 7.3412\n",
      "Epoch 35/50 | Loss: 9.1215\n",
      "Epoch 36/50 | Loss: 7.1654\n",
      "Epoch 37/50 | Loss: 7.4651\n",
      "Epoch 38/50 | Loss: 8.4267\n",
      "Epoch 39/50 | Loss: 8.1625\n",
      "Epoch 40/50 | Loss: 8.3156\n",
      "Epoch 41/50 | Loss: 7.9046\n",
      "Epoch 42/50 | Loss: 10.1677\n",
      "Epoch 43/50 | Loss: 7.4287\n",
      "Epoch 44/50 | Loss: 8.7351\n",
      "Epoch 45/50 | Loss: 8.9896\n",
      "Epoch 46/50 | Loss: 7.8890\n",
      "Epoch 47/50 | Loss: 7.8638\n",
      "Epoch 48/50 | Loss: 8.1847\n",
      "Epoch 49/50 | Loss: 7.6022\n",
      "Epoch 50/50 | Loss: 7.9431\n",
      "Output shape: (219, 1, 100)\n"
     ]
    }
   ],
   "source": [
    "# === 1. Load & preprocess METABRIC ===\n",
    "df = pd.read_csv(\"data/METABRIC_RNA_Mutation.csv\")  # example filename\n",
    "df = preprocess_metabrics(df)\n",
    "data = prepare_deephit_data(df, num_bins=100)\n",
    "\n",
    "train = data[\"train\"]\n",
    "test = data[\"test\"]\n",
    "meta = data[\"meta\"]\n",
    "\n",
    "# === 2. Initialize model ===\n",
    "network_settings = {\n",
    "    \"h_dim_shared\": 64,\n",
    "    \"h_dim_CS\": 32,\n",
    "    \"num_layers_shared\": 2,\n",
    "    \"num_layers_CS\": 2,\n",
    "    \"active_fn\": \"relu\",\n",
    "    \"keep_prob\": 0.8,\n",
    "}\n",
    "\n",
    "model = DeepHit(meta, network_settings)\n",
    "optimizer = Adam(learning_rate=1e-3)\n",
    "\n",
    "# === 3. Convert NumPy arrays â†’ TensorFlow tensors ===\n",
    "x_train = tf.convert_to_tensor(train[\"x\"], dtype=tf.float32)\n",
    "t_train = tf.convert_to_tensor(train[\"t\"], dtype=tf.int32)\n",
    "e_train = tf.convert_to_tensor(train[\"e\"], dtype=tf.int32)\n",
    "m1_train = tf.convert_to_tensor(train[\"m1\"], dtype=tf.float32)\n",
    "m2_train = tf.convert_to_tensor(train[\"m2\"], dtype=tf.float32)\n",
    "\n",
    "x_test = tf.convert_to_tensor(test[\"x\"], dtype=tf.float32)\n",
    "t_test = tf.convert_to_tensor(test[\"t\"], dtype=tf.int32)\n",
    "e_test = tf.convert_to_tensor(test[\"e\"], dtype=tf.int32)\n",
    "m1_test = tf.convert_to_tensor(test[\"m1\"], dtype=tf.float32)\n",
    "m2_test = tf.convert_to_tensor(test[\"m2\"], dtype=tf.float32)\n",
    "\n",
    "# === 4. Train loop ===\n",
    "alpha, beta, gamma = 1.0, 1.0, 0.0  # you can tune these\n",
    "epochs = 50\n",
    "batch_size = 128\n",
    "num_samples = x_train.shape[0]\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    # Shuffle training data\n",
    "    idx = tf.random.shuffle(tf.range(num_samples))\n",
    "    x_train = tf.gather(x_train, idx)\n",
    "    t_train = tf.gather(t_train, idx)\n",
    "    e_train = tf.gather(e_train, idx)\n",
    "    m1_train = tf.gather(m1_train, idx)\n",
    "    m2_train = tf.gather(m2_train, idx)\n",
    "\n",
    "    # Mini-batch training\n",
    "    for i in range(0, num_samples, batch_size):\n",
    "        xb = x_train[i : i + batch_size]\n",
    "        tb = t_train[i : i + batch_size]\n",
    "        eb = e_train[i : i + batch_size]\n",
    "        m1b = m1_train[i : i + batch_size]\n",
    "        m2b = m2_train[i : i + batch_size]\n",
    "\n",
    "        with tf.GradientTape() as tape:\n",
    "            loss, _ = model.compute_loss(xb, eb, tb, m1b, m2b, alpha, beta, gamma)\n",
    "        grads = tape.gradient(loss, model.trainable_variables)\n",
    "        optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {loss.numpy():.4f}\")\n",
    "\n",
    "# === 5. Inference ===\n",
    "out_test = model(x_test, training=False)\n",
    "print(\"Output shape:\", out_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eec2a369",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv (3.7.12)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
